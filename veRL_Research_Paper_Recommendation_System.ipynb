{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required dependencies\n",
        "!pip install gradio torch sentence-transformers pandas numpy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pickle\n",
        "import json\n",
        "from collections import deque\n",
        "import random\n",
        "import sqlite3\n",
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "# Define the RL model architecture\n",
        "class RLRecommender(nn.Module):\n",
        "    def __init__(self, state_dim: int, action_dim: int, hidden_dim: int = 256):\n",
        "        super(RLRecommender, self).__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(state_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, action_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, state):\n",
        "        return self.network(state)\n",
        "\n",
        "# Generate sample data\n",
        "class ResearchPaperDataset:\n",
        "    def __init__(self):\n",
        "        self.paper_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.papers = {}\n",
        "        self.paper_embeddings = {}\n",
        "\n",
        "    def generate_sample_data(self, num_papers=200):\n",
        "        \"\"\"Generate realistic sample research paper data\"\"\"\n",
        "        categories = {\n",
        "            'ML': ['Deep Learning', 'Reinforcement Learning', 'Supervised Learning', 'Unsupervised Learning'],\n",
        "            'NLP': ['Transformers', 'Language Models', 'Text Generation', 'Sentiment Analysis'],\n",
        "            'CV': ['Object Detection', 'Image Segmentation', 'GANs', 'Neural Rendering'],\n",
        "            'RL': ['Q-Learning', 'Policy Gradients', 'Multi-Agent', 'Imitation Learning'],\n",
        "            'AI': ['Ethics', 'Theory', 'Applications', 'Systems']\n",
        "        }\n",
        "\n",
        "        venues = ['NeurIPS', 'ICML', 'ICLR', 'ACL', 'CVPR', 'AAAI', 'IJCAI']\n",
        "        research_topics = [\n",
        "            \"Efficient Transformers for Long Sequences\",\n",
        "            \"Multi-Modal Learning with Vision-Language Models\",\n",
        "            \"Robust Deep Learning against Adversarial Attacks\",\n",
        "            \"Self-Supervised Learning Paradigms\",\n",
        "            \"Federated Learning for Privacy Preservation\",\n",
        "            \"Explainable AI for Medical Diagnostics\",\n",
        "            \"Reinforcement Learning from Human Feedback\",\n",
        "            \"Graph Neural Networks for Social Networks\",\n",
        "            \"Quantum Machine Learning Applications\",\n",
        "            \"Meta-Learning for Few-Shot Classification\",\n",
        "            \"Large Language Model Fine-tuning\",\n",
        "            \"Computer Vision for Autonomous Driving\",\n",
        "            \"Neural Architecture Search\",\n",
        "            \"AI for Scientific Discovery\",\n",
        "            \"Multimodal Representation Learning\"\n",
        "        ]\n",
        "\n",
        "        sample_papers = []\n",
        "        for i in range(num_papers):\n",
        "            category = random.choice(list(categories.keys()))\n",
        "            subcategory = random.choice(categories[category])\n",
        "            research_topic = random.choice(research_topics)\n",
        "\n",
        "            paper = {\n",
        "                'paper_id': f'paper_{i:04d}',\n",
        "                'title': f'Advancements in {research_topic}',\n",
        "                'abstract': f'This paper presents novel research in {category} focusing on {subcategory}. We introduce a new methodology that significantly improves upon existing approaches in {research_topic}. Our experiments demonstrate state-of-the-art performance on benchmark datasets with comprehensive ablation studies and real-world applications.',\n",
        "                'authors': [f'Researcher_{j}' for j in range(1, 2 + i % 4)],\n",
        "                'categories': [category, subcategory],\n",
        "                'venue': random.choice(venues),\n",
        "                'year': 2020 + (i % 4),\n",
        "                'citations': random.randint(0, 200)\n",
        "            }\n",
        "            sample_papers.append(paper)\n",
        "\n",
        "        return sample_papers\n",
        "\n",
        "    def create_embeddings(self, papers: list):\n",
        "        \"\"\"Create embeddings for all papers\"\"\"\n",
        "        print(\"Creating paper embeddings...\")\n",
        "\n",
        "        for paper in papers:\n",
        "            paper_id = paper['paper_id']\n",
        "            self.papers[paper_id] = paper\n",
        "\n",
        "            # Create embedding from title and abstract\n",
        "            text = paper['title'] + \" \" + paper['abstract']\n",
        "            embedding = self.paper_model.encode(text)\n",
        "            self.paper_embeddings[paper_id] = embedding\n",
        "\n",
        "        print(f\"Created embeddings for {len(self.papers)} papers\")\n",
        "\n",
        "# Initialize dataset\n",
        "print(\"üìö Initializing research paper dataset...\")\n",
        "dataset = ResearchPaperDataset()\n",
        "sample_papers = dataset.generate_sample_data(200)\n",
        "dataset.create_embeddings(sample_papers)\n",
        "\n",
        "print(f\"‚úÖ Dataset ready: {len(dataset.papers)} papers loaded\")\n",
        "\n",
        "# Create a simple trained model\n",
        "def create_pretrained_model():\n",
        "    \"\"\"Create a pre-trained model for demonstration\"\"\"\n",
        "    state_dim = 386  # 384 (embedding) + 2 (metrics)\n",
        "    action_dim = len(dataset.papers)\n",
        "\n",
        "    model = RLRecommender(state_dim, action_dim)\n",
        "\n",
        "    # Simulate some training by setting reasonable weights\n",
        "    for layer in model.network:\n",
        "        if hasattr(layer, 'weight'):\n",
        "            nn.init.xavier_normal_(layer.weight)\n",
        "            if hasattr(layer, 'bias'):\n",
        "                nn.init.constant_(layer.bias, 0)\n",
        "\n",
        "    return model\n",
        "\n",
        "trained_model = create_pretrained_model()\n",
        "\n",
        "# Research Recommendation System\n",
        "class ResearchRecommendationSystem:\n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.agent = trained_model.to(self.device)\n",
        "        self.agent.eval()\n",
        "        self.paper_embeddings = dataset.paper_embeddings\n",
        "        self.available_papers = list(self.paper_embeddings.keys())\n",
        "        self.papers = dataset.papers\n",
        "        self.user_states = {}\n",
        "        self.setup_database()\n",
        "\n",
        "    def setup_database(self):\n",
        "        \"\"\"Setup SQLite database for user data\"\"\"\n",
        "        self.conn = sqlite3.connect('gradio_recommendation.db', check_same_thread=False)\n",
        "        cursor = self.conn.cursor()\n",
        "\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS users (\n",
        "                user_id TEXT PRIMARY KEY,\n",
        "                interest_embedding BLOB,\n",
        "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS interactions (\n",
        "                interaction_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                user_id TEXT,\n",
        "                paper_id TEXT,\n",
        "                action_type TEXT,\n",
        "                reward REAL,\n",
        "                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        self.conn.commit()\n",
        "\n",
        "    def get_or_create_user(self, user_id: str):\n",
        "        \"\"\"Get user data or create new user\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "\n",
        "        cursor.execute('SELECT interest_embedding FROM users WHERE user_id = ?', (user_id,))\n",
        "        result = cursor.fetchone()\n",
        "\n",
        "        if result:\n",
        "            interest_embedding = pickle.loads(result[0])\n",
        "        else:\n",
        "            interest_embedding = np.random.normal(0, 0.1, 384)\n",
        "            cursor.execute(\n",
        "                'INSERT INTO users (user_id, interest_embedding) VALUES (?, ?)',\n",
        "                (user_id, pickle.dumps(interest_embedding))\n",
        "            )\n",
        "            self.conn.commit()\n",
        "\n",
        "        return interest_embedding\n",
        "\n",
        "    def update_user_interests(self, user_id: str, paper_embedding: np.ndarray, reward: float):\n",
        "        \"\"\"Update user interests based on interaction\"\"\"\n",
        "        current_embedding = self.get_or_create_user(user_id)\n",
        "\n",
        "        learning_rate = 0.1 * reward\n",
        "        new_embedding = (1 - learning_rate) * current_embedding + learning_rate * paper_embedding\n",
        "        new_embedding = new_embedding / np.linalg.norm(new_embedding)\n",
        "\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\n",
        "            'UPDATE users SET interest_embedding = ? WHERE user_id = ?',\n",
        "            (pickle.dumps(new_embedding), user_id)\n",
        "        )\n",
        "        self.conn.commit()\n",
        "\n",
        "        return new_embedding\n",
        "\n",
        "    def log_interaction(self, user_id: str, paper_id: str, action_type: str, reward: float):\n",
        "        \"\"\"Log user interaction\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\n",
        "            'INSERT INTO interactions (user_id, paper_id, action_type, reward) VALUES (?, ?, ?, ?)',\n",
        "            (user_id, paper_id, action_type, reward)\n",
        "        )\n",
        "        self.conn.commit()\n",
        "\n",
        "    def get_user_state(self, user_id: str):\n",
        "        \"\"\"Get current user state for RL agent\"\"\"\n",
        "        interest_embedding = self.get_or_create_user(user_id)\n",
        "\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute('''\n",
        "            SELECT reward FROM interactions\n",
        "            WHERE user_id = ?\n",
        "            ORDER BY timestamp DESC LIMIT 10\n",
        "        ''', (user_id,))\n",
        "\n",
        "        recent_rewards = [row[0] for row in cursor.fetchall()]\n",
        "        avg_reward = np.mean(recent_rewards) if recent_rewards else 0\n",
        "\n",
        "        state = np.concatenate([\n",
        "            interest_embedding,\n",
        "            [avg_reward, len(recent_rewards)]\n",
        "        ])\n",
        "\n",
        "        return state\n",
        "\n",
        "    def get_recommendations(self, user_id: str, num_recommendations: int = 5):\n",
        "        \"\"\"Get personalized paper recommendations\"\"\"\n",
        "        user_state = self.get_user_state(user_id)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            state_tensor = torch.FloatTensor(user_state).unsqueeze(0).to(self.device)\n",
        "            q_values = self.agent(state_tensor)\n",
        "            top_actions = q_values.argsort(descending=True)[0][:num_recommendations]\n",
        "\n",
        "        recommendations = []\n",
        "        for action in top_actions:\n",
        "            paper_id = self.available_papers[action.item()]\n",
        "            paper_embedding = self.paper_embeddings[paper_id]\n",
        "\n",
        "            user_embedding = self.get_or_create_user(user_id)\n",
        "            interest_score = np.dot(user_embedding, paper_embedding) / (\n",
        "                np.linalg.norm(user_embedding) * np.linalg.norm(paper_embedding)\n",
        "            )\n",
        "\n",
        "            paper_info = self.papers[paper_id].copy()\n",
        "            paper_info['paper_id'] = paper_id\n",
        "            paper_info['interest_score'] = float(interest_score)\n",
        "\n",
        "            recommendations.append(paper_info)\n",
        "\n",
        "        return sorted(recommendations, key=lambda x: x['interest_score'], reverse=True)\n",
        "\n",
        "    def process_feedback(self, user_id: str, paper_id: str, action: str):\n",
        "        \"\"\"Process user feedback and update models\"\"\"\n",
        "        paper_embedding = self.paper_embeddings.get(paper_id)\n",
        "        if paper_embedding is None:\n",
        "            return False\n",
        "\n",
        "        reward_map = {\n",
        "            'read': 0.7,\n",
        "            'save': 1.0,\n",
        "            'skip': -0.1,\n",
        "            'dislike': -0.5\n",
        "        }\n",
        "\n",
        "        reward = reward_map.get(action, 0.0)\n",
        "\n",
        "        self.update_user_interests(user_id, paper_embedding, reward)\n",
        "        self.log_interaction(user_id, paper_id, action, reward)\n",
        "\n",
        "        return True\n",
        "\n",
        "    def get_user_stats(self, user_id: str):\n",
        "        \"\"\"Get user statistics\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute('''\n",
        "            SELECT COUNT(*), AVG(reward) FROM interactions WHERE user_id = ?\n",
        "        ''', (user_id,))\n",
        "\n",
        "        count_result = cursor.fetchone()\n",
        "        total_interactions = count_result[0] if count_result[0] else 0\n",
        "        avg_reward = count_result[1] if count_result[1] else 0\n",
        "\n",
        "        cursor.execute('''\n",
        "            SELECT action_type, COUNT(*) FROM interactions\n",
        "            WHERE user_id = ? GROUP BY action_type\n",
        "        ''', (user_id,))\n",
        "\n",
        "        action_counts = dict(cursor.fetchall())\n",
        "\n",
        "        return {\n",
        "            'total_interactions': total_interactions,\n",
        "            'average_reward': avg_reward,\n",
        "            'action_counts': action_counts\n",
        "        }\n",
        "\n",
        "# Initialize the recommendation system\n",
        "print(\"üöÄ Initializing Recommendation System...\")\n",
        "recommender = ResearchRecommendationSystem()\n",
        "\n",
        "# Gradio Interface Functions\n",
        "def get_recommendations_interface(user_id, num_recommendations):\n",
        "    \"\"\"Gradio interface for getting recommendations\"\"\"\n",
        "    if not user_id.strip():\n",
        "        return \"‚ö†Ô∏è Please enter a User ID\", \"\", \"\"\n",
        "\n",
        "    try:\n",
        "        recommendations = recommender.get_recommendations(user_id, num_recommendations)\n",
        "\n",
        "        if not recommendations:\n",
        "            return \"‚ùå No recommendations found. Try interacting with some papers first!\", \"\", \"\"\n",
        "\n",
        "        # Format recommendations for display\n",
        "        recommendations_text = \"\"\n",
        "        recommendations_html = \"\"\n",
        "        paper_ids = []\n",
        "\n",
        "        for i, paper in enumerate(recommendations, 1):\n",
        "            match_percent = paper['interest_score'] * 100\n",
        "            recommendations_text += f\"{i}. {paper['title']}\\n\"\n",
        "            recommendations_text += f\"   Match: {match_percent:.1f}% | Venue: {paper['venue']} | Year: {paper['year']}\\n\"\n",
        "            recommendations_text += f\"   Categories: {', '.join(paper['categories'])}\\n\"\n",
        "            recommendations_text += f\"   Citations: {paper['citations']}\\n\"\n",
        "            recommendations_text += f\"   Abstract: {paper['abstract'][:150]}...\\n\\n\"\n",
        "\n",
        "            recommendations_html += f\"\"\"\n",
        "            <div style=\"border: 1px solid #e0e0e0; padding: 15px; margin: 10px 0; border-radius: 8px; background: white;\">\n",
        "                <h3 style=\"margin: 0 0 10px 0; color: #2c3e50;\">{i}. {paper['title']}</h3>\n",
        "                <div style=\"display: flex; gap: 10px; margin-bottom: 10px; flex-wrap: wrap;\">\n",
        "                    <span style=\"background: #e74c3c; color: white; padding: 4px 8px; border-radius: 12px; font-size: 0.9em;\">\n",
        "                        {match_percent:.1f}% Match\n",
        "                    </span>\n",
        "                    <span style=\"background: #3498db; color: white; padding: 4px 8px; border-radius: 12px; font-size: 0.9em;\">\n",
        "                        {paper['venue']} {paper['year']}\n",
        "                    </span>\n",
        "                    <span style=\"background: #27ae60; color: white; padding: 4px 8px; border-radius: 12px; font-size: 0.9em;\">\n",
        "                        {paper['citations']} Citations\n",
        "                    </span>\n",
        "                </div>\n",
        "                <p style=\"margin: 5px 0; color: #7f8c8d;\"><strong>Categories:</strong> {', '.join(paper['categories'])}</p>\n",
        "                <p style=\"margin: 10px 0; color: #5d6d7e; line-height: 1.4;\">{paper['abstract']}</p>\n",
        "                <div style=\"display: flex; gap: 10px; margin-top: 10px;\">\n",
        "                    <button onclick='provideFeedback(\"{paper['paper_id']}\", \"read\")' style=\"background: #3498db; color: white; border: none; padding: 8px 15px; border-radius: 5px; cursor: pointer;\">üìñ Read</button>\n",
        "                    <button onclick='provideFeedback(\"{paper['paper_id']}\", \"save\")' style=\"background: #27ae60; color: white; border: none; padding: 8px 15px; border-radius: 5px; cursor: pointer;\">üíæ Save</button>\n",
        "                    <button onclick='provideFeedback(\"{paper['paper_id']}\", \"skip\")' style=\"background: #95a5a6; color: white; border: none; padding: 8px 15px; border-radius: 5px; cursor: pointer;\">‚è≠Ô∏è Skip</button>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            paper_ids.append(paper['paper_id'])\n",
        "\n",
        "        stats = recommender.get_user_stats(user_id)\n",
        "        stats_text = f\"User: {user_id} | Total Interactions: {stats['total_interactions']} | Avg Reward: {stats['average_reward']:.2f}\"\n",
        "\n",
        "        return recommendations_text, recommendations_html, stats_text\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\", \"\", \"\"\n",
        "\n",
        "def provide_feedback_interface(user_id, paper_id, action):\n",
        "    \"\"\"Gradio interface for providing feedback\"\"\"\n",
        "    if not user_id.strip() or not paper_id.strip():\n",
        "        return \"‚ö†Ô∏è Please enter both User ID and Paper ID\"\n",
        "\n",
        "    try:\n",
        "        success = recommender.process_feedback(user_id, paper_id, action)\n",
        "\n",
        "        if success:\n",
        "            reward_map = {'read': 0.7, 'save': 1.0, 'skip': -0.1, 'dislike': -0.5}\n",
        "            reward = reward_map.get(action, 0.0)\n",
        "            return f\"‚úÖ Feedback recorded! {action.capitalize()} action (reward: {reward:+.1f}) - The system is learning from your preferences!\"\n",
        "        else:\n",
        "            return \"‚ùå Failed to record feedback\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "def get_user_profile_interface(user_id):\n",
        "    \"\"\"Gradio interface for getting user profile\"\"\"\n",
        "    if not user_id.strip():\n",
        "        return \"‚ö†Ô∏è Please enter a User ID\"\n",
        "\n",
        "    try:\n",
        "        stats = recommender.get_user_stats(user_id)\n",
        "\n",
        "        profile_text = f\"üìä User Profile: {user_id}\\n\"\n",
        "        profile_text += f\"üìà Total Interactions: {stats['total_interactions']}\\n\"\n",
        "        profile_text += f\"‚≠ê Average Reward: {stats['average_reward']:.2f}\\n\"\n",
        "        profile_text += \"\\nüìã Action Breakdown:\\n\"\n",
        "\n",
        "        for action, count in stats['action_counts'].items():\n",
        "            profile_text += f\"   ‚Ä¢ {action.capitalize()}: {count} times\\n\"\n",
        "\n",
        "        # Get recent recommendations to show learning progress\n",
        "        recommendations = recommender.get_recommendations(user_id, 3)\n",
        "        if recommendations:\n",
        "            profile_text += f\"\\nüéØ Recent Top Matches:\\n\"\n",
        "            for i, paper in enumerate(recommendations[:3], 1):\n",
        "                profile_text += f\"   {i}. {paper['title']} ({paper['interest_score']:.2f})\\n\"\n",
        "\n",
        "        return profile_text\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "# Create Gradio Interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"AI Research Paper Recommender\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ü§ñ AI Research Paper Recommendation System\n",
        "    ## Powered by Reinforcement Learning\n",
        "\n",
        "    Discover personalized research papers that match your interests! The system learns from your feedback to improve recommendations over time.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            user_id = gr.Textbox(\n",
        "                label=\"User ID\",\n",
        "                value=\"gradio_user_001\",\n",
        "                placeholder=\"Enter your user ID...\",\n",
        "                info=\"Try: gradio_user_001, gradio_user_002, or create a new ID\"\n",
        "            )\n",
        "\n",
        "            num_recommendations = gr.Slider(\n",
        "                minimum=1,\n",
        "                maximum=10,\n",
        "                value=5,\n",
        "                step=1,\n",
        "                label=\"Number of Recommendations\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                get_recs_btn = gr.Button(\"üéØ Get Recommendations\", variant=\"primary\")\n",
        "                profile_btn = gr.Button(\"üìä View Profile\")\n",
        "\n",
        "            gr.Markdown(\"### üîÑ Provide Feedback\")\n",
        "            with gr.Row():\n",
        "                paper_id_feedback = gr.Textbox(\n",
        "                    label=\"Paper ID\",\n",
        "                    placeholder=\"Enter paper ID from recommendations...\"\n",
        "                )\n",
        "                action_type = gr.Dropdown(\n",
        "                    choices=[\"read\", \"save\", \"skip\", \"dislike\"],\n",
        "                    label=\"Action\",\n",
        "                    value=\"read\"\n",
        "                )\n",
        "\n",
        "            feedback_btn = gr.Button(\"üíæ Submit Feedback\")\n",
        "            feedback_output = gr.Textbox(label=\"Feedback Result\", interactive=False)\n",
        "\n",
        "            profile_output = gr.Textbox(\n",
        "                label=\"User Profile\",\n",
        "                lines=10,\n",
        "                max_lines=15,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            recommendations_output = gr.Textbox(\n",
        "                label=\"Recommendations (Text)\",\n",
        "                lines=15,\n",
        "                max_lines=20,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "            html_output = gr.HTML(\n",
        "                label=\"Recommendations (Visual)\"\n",
        "            )\n",
        "\n",
        "            stats_output = gr.Textbox(\n",
        "                label=\"User Statistics\",\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "    # Event handlers\n",
        "    get_recs_btn.click(\n",
        "        fn=get_recommendations_interface,\n",
        "        inputs=[user_id, num_recommendations],\n",
        "        outputs=[recommendations_output, html_output, stats_output]\n",
        "    )\n",
        "\n",
        "    profile_btn.click(\n",
        "        fn=get_user_profile_interface,\n",
        "        inputs=[user_id],\n",
        "        outputs=[profile_output]\n",
        "    )\n",
        "\n",
        "    feedback_btn.click(\n",
        "        fn=provide_feedback_interface,\n",
        "        inputs=[user_id, paper_id_feedback, action_type],\n",
        "        outputs=[feedback_output]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ### üéØ How to Use:\n",
        "    1. **Enter your User ID** (or use a demo user)\n",
        "    2. **Click \"Get Recommendations\"** to see personalized papers\n",
        "    3. **Provide feedback** by entering Paper ID and selecting an action\n",
        "    4. **View your profile** to see your interaction history\n",
        "    5. **Watch the system learn** from your preferences!\n",
        "\n",
        "    ### üìä Reward System:\n",
        "    - üìñ **Read**: +0.7 points\n",
        "    - üíæ **Save**: +1.0 points\n",
        "    - ‚è≠Ô∏è **Skip**: -0.1 points\n",
        "    - üëé **Dislike**: -0.5 points\n",
        "\n",
        "    The reinforcement learning model uses these rewards to continuously improve your recommendations!\n",
        "    \"\"\")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "print(\"üöÄ Launching Gradio Interface...\")\n",
        "print(\"‚úÖ System ready! The interface will open below.\")\n",
        "print(\"üìö Available research papers:\", len(dataset.papers))\n",
        "print(\"ü§ñ RL model initialized and ready!\")\n",
        "\n",
        "# Test the system\n",
        "print(\"\\nüß™ Running quick test...\")\n",
        "test_recommendations = recommender.get_recommendations(\"test_user\", 2)\n",
        "if test_recommendations:\n",
        "    print(\"‚úÖ System test passed! Recommendations generated successfully.\")\n",
        "    for i, paper in enumerate(test_recommendations, 1):\n",
        "        print(f\"   {i}. {paper['title']} ({paper['interest_score']:.2f})\")\n",
        "else:\n",
        "    print(\"‚ùå System test failed.\")\n",
        "\n",
        "print(\"\\nüéØ Demo Users to try:\")\n",
        "print(\"   - gradio_user_001\")\n",
        "print(\"   - gradio_user_002\")\n",
        "print(\"   - gradio_user_003\")\n",
        "print(\"   - Or create any new user ID!\")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5WSVRs_Q59da",
        "outputId": "af116d78-1e23-45d0-f7df-dad3fca329af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.121.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.4)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "üìö Initializing research paper dataset...\n",
            "Creating paper embeddings...\n",
            "Created embeddings for 200 papers\n",
            "‚úÖ Dataset ready: 200 papers loaded\n",
            "üöÄ Initializing Recommendation System...\n",
            "üöÄ Launching Gradio Interface...\n",
            "‚úÖ System ready! The interface will open below.\n",
            "üìö Available research papers: 200\n",
            "ü§ñ RL model initialized and ready!\n",
            "\n",
            "üß™ Running quick test...\n",
            "‚úÖ System test passed! Recommendations generated successfully.\n",
            "   1. Advancements in Multimodal Representation Learning (0.00)\n",
            "   2. Advancements in Quantum Machine Learning Applications (-0.00)\n",
            "\n",
            "üéØ Demo Users to try:\n",
            "   - gradio_user_001\n",
            "   - gradio_user_002\n",
            "   - gradio_user_003\n",
            "   - Or create any new user ID!\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://709e45bee19c4808c5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://709e45bee19c4808c5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://709e45bee19c4808c5.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4PyeRWn5-cE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}